{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Event Matching and Match Evaluation",
   "id": "e4c884fb34121189"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import peyes"
   ],
   "id": "ef6eea84d69d986b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Preparing the Data\n",
    "As shown in previous notebooks, we start by preparing the data.  \n",
    "In the following code blocks we:  \n",
    "1. Download the \"Lund2013\" dataset.  \n",
    "2. Extract the data of the first trial, including the time, x, and y columns as well as the pixel size and viewer distance.  \n",
    "3. Extract the annotations by the two human annotators _\"RA\"_ and _\"MN\"_. These will be used as the ground truth for the upcoming evaluation.  \n",
    "4. Create two detector objects, using Engbert's detection algorithm and the I-VT detection algorithm.  \n",
    "5. Use each detector to label the samples in the first trial.  "
   ],
   "id": "710351855453301c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Download the \"Lund2013\" dataset\n",
    "dataset = peyes.datasets.lund2013(directory=None, save=False, verbose=True)\n",
    "\n",
    "# Extract the data of the first trial\n",
    "trial1_data = dataset[dataset[peyes.constants.TRIAL_ID_STR] == 1]\n",
    "\n",
    "# read labels from the two annotators\n",
    "ra = trial1_data[\"RA\"].values\n",
    "mn = trial1_data[\"MN\"].values\n",
    "\n",
    "# Extract the time, x, and y columns as well as the pixel size and viewer distance\n",
    "trial1_t = trial1_data[peyes.constants.T].values\n",
    "trial1_x = trial1_data[peyes.constants.X].values\n",
    "trial1_y = trial1_data[peyes.constants.Y].values\n",
    "trial1_p = trial1_data[peyes.constants.PUPIL].values\n",
    "trial1_pixel_size = trial1_data[\"pixel_size\"].values[0]\n",
    "trial1_viewer_distance = trial1_data[\"viewer_distance\"].values[0]\n",
    "\n",
    "# create detector objects and use them to detect the samples in the first trial\n",
    "engbert = peyes.create_detector(\"engbert\", missing_value=np.nan, min_event_duration=4, pad_blinks_time=0)\n",
    "eng_labels, eng_metadata = engbert.detect(\n",
    "    t=trial1_t, x=trial1_x, y=trial1_y, pixel_size_cm=trial1_pixel_size, viewer_distance_cm=trial1_viewer_distance\n",
    ")\n",
    "\n",
    "ivt = peyes.create_detector(\"ivt\", missing_value=np.nan, min_event_duration=4, pad_blinks_time=0)\n",
    "ivt_labels, ivt_metadata = ivt.detect(\n",
    "    t=trial1_t, x=trial1_x, y=trial1_y, pixel_size_cm=trial1_pixel_size, viewer_distance_cm=trial1_viewer_distance\n",
    ")"
   ],
   "id": "e066fa1bcc560489"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Generating Events\n",
    "As shown in notebook #1, consecutive samples that share the same label can be grouped into an `Event` object.  \n",
    "These are one of `pEYES`'s data structures, and they contain many useful attributes and methods that are easier to use than manipulating the raw data directly. For example, we can use an `Event` object to calculate the duration of the event, instead of manually calculating the difference between the start and end times of the samples that compose the event.  \n",
    "\n",
    "To convert `pEYES`'s labels to events, we use the `peyes.create_events()` function (see notebook #1 for more details).  \n",
    "As another preparatory step, we will convert the labels from all annotators and detectors to their corresponding events."
   ],
   "id": "da77acc0c60d8dd5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "ra_events = peyes.create_events(\n",
    "    labels=ra,\n",
    "    t=trial1_t, x=trial1_x, y=trial1_y, pupil=trial1_p,\n",
    "    pixel_size=trial1_pixel_size, viewer_distance=trial1_viewer_distance\n",
    ")\n",
    "mn_events = peyes.create_events(\n",
    "    labels=mn,\n",
    "    t=trial1_t, x=trial1_x, y=trial1_y, pupil=trial1_p,\n",
    "    pixel_size=trial1_pixel_size, viewer_distance=trial1_viewer_distance\n",
    ")\n",
    "eng_events = peyes.create_events(\n",
    "    labels=eng_labels,\n",
    "    t=trial1_t, x=trial1_x, y=trial1_y, pupil=trial1_p,\n",
    "    pixel_size=trial1_pixel_size, viewer_distance=trial1_viewer_distance\n",
    ")\n",
    "ivt_events = peyes.create_events(\n",
    "    labels=ivt_labels,\n",
    "    t=trial1_t, x=trial1_x, y=trial1_y, pupil=trial1_p,\n",
    "    pixel_size=trial1_pixel_size, viewer_distance=trial1_viewer_distance\n",
    ")"
   ],
   "id": "f74459b6ace68069"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "63a8002fc405bf2b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5f8c4314c6815e5f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "736a8bd0880a6354"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
